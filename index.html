<meta name='viewport' content='width=device-width, initial-scale=1'/><!DOCTYPE html>
<html lang="nl">
<head>
  <meta charset="UTF-8">
  <title>Scratch Lab</title>
  <style>
    body { font-family: sans-serif; padding: 1rem; text-align: center; background: #111; color: #eee; }
    canvas { border: 1px solid #444; margin: 1rem 0; background: #222; }
    button, input { margin: 0.5rem; padding: 0.6rem 1rem; font-size: 1rem; }
  </style>
</head>
<body>
  <h1>üéö Scratch Lab</h1>
  <button id="recordBtn">üî¥ Start opname</button>
  <button id="stopBtn" disabled>‚èπ Stop opname</button>
  <button id="renderBtn" disabled>üéß Render Scratch</button>
  <div><label>BPM: <input id="bpm" type="number" value="100" min="60" max="180"></label></div>

  <h3>Waveform + Cue</h3>
  <canvas id="waveform" width="600" height="150"></canvas>

  <h3>Curve Editor (teken scratch)</h3>
  <canvas id="curveEditor" width="600" height="150"></canvas>
  <div><button id="clearCurve">üßπ Clear</button></div>

  <div id="output"></div>

  <script>
    const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    let mediaRecorder, chunks = [], recordedBuffer;
    let curvePoints = [];

    const recordBtn = document.getElementById("recordBtn");
    const stopBtn = document.getElementById("stopBtn");
    const renderBtn = document.getElementById("renderBtn");
    const bpmInput = document.getElementById("bpm");
    const waveformCanvas = document.getElementById("waveform");
    const curveCanvas = document.getElementById("curveEditor");
    const output = document.getElementById("output");
    const wfCtx = waveformCanvas.getContext("2d");
    const cvCtx = curveCanvas.getContext("2d");

    // üé§ Opname
    recordBtn.onclick = async () => {
      audioCtx.resume();
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(stream);
      chunks = [];
      mediaRecorder.ondataavailable = e => chunks.push(e.data);
      mediaRecorder.onstop = async () => {
        const blob = new Blob(chunks, { type: "audio/webm" });
        const buf = await blob.arrayBuffer();
        recordedBuffer = await audioCtx.decodeAudioData(buf);
        renderBtn.disabled = false;
        drawWaveform(recordedBuffer);
        output.innerHTML = "<p>‚úÖ Opname klaar! Teken een scratch-curve.</p>";
      };
      mediaRecorder.start();
      recordBtn.disabled = true;
      stopBtn.disabled = false;
    };

    stopBtn.onclick = () => {
      mediaRecorder.stop();
      stopBtn.disabled = true;
      recordBtn.disabled = false;
    };

    // üé® Waveform tekenen
    function drawWaveform(buffer) {
      const data = buffer.getChannelData(0);
      wfCtx.fillStyle = "#222";
      wfCtx.fillRect(0,0,waveformCanvas.width,waveformCanvas.height);
      wfCtx.strokeStyle = "#0f0";
      wfCtx.beginPath();
      const step = Math.floor(data.length / waveformCanvas.width);
      for (let i = 0; i < waveformCanvas.width; i++) {
        const min = data[i*step];
        const y = (1 - (min + 1) / 2) * waveformCanvas.height;
        wfCtx.lineTo(i, y);
      }
      wfCtx.stroke();
    }

    // üñäÔ∏è Curve editor (muis/touch)
    let drawing = false;
    function drawCurve() {
      cvCtx.fillStyle = "#222";
      cvCtx.fillRect(0,0,curveCanvas.width,curveCanvas.height);
      cvCtx.strokeStyle = "#0af";
      cvCtx.beginPath();
      curvePoints.forEach((p,i)=>{
        const y = curveCanvas.height/2 - p*curveCanvas.height/2;
        if(i===0) cvCtx.moveTo(i, y);
        else cvCtx.lineTo(i, y);
      });
      cvCtx.stroke();
    }
    curveCanvas.onmousedown = e => { drawing = true; curvePoints=[]; };
    curveCanvas.onmouseup = e => { drawing = false; };
    curveCanvas.onmousemove = e => {
      if(drawing){
        const rect = curveCanvas.getBoundingClientRect();
        const x = e.clientX - rect.left;
        const y = e.clientY - rect.top;
        const norm = (curveCanvas.height/2 - y) / (curveCanvas.height/2);
        curvePoints[Math.floor(x)] = Math.max(-1, Math.min(1, norm));
        drawCurve();
      }
    };
    // Touch
    curveCanvas.ontouchstart = e => { drawing = true; curvePoints=[]; e.preventDefault(); };
    curveCanvas.ontouchend = e => { drawing = false; e.preventDefault(); };
    curveCanvas.ontouchmove = e => {
      if(drawing){
        const rect = curveCanvas.getBoundingClientRect();
        const x = e.touches[0].clientX - rect.left;
        const y = e.touches[0].clientY - rect.top;
        const norm = (curveCanvas.height/2 - y) / (curveCanvas.height/2);
        curvePoints[Math.floor(x)] = Math.max(-1, Math.min(1, norm));
        drawCurve();
      }
      e.preventDefault();
    };

    document.getElementById("clearCurve").onclick = ()=>{ curvePoints=[]; drawCurve(); };

    // ü™Ñ Scratch render
    renderBtn.onclick = async () => {
      if(!curvePoints.length){ output.innerHTML="<p>‚ùå Eerst curve tekenen!</p>"; return; }
      const bpm = parseInt(bpmInput.value);
      const beatDur = 60 / bpm;
      const duration = beatDur * 4;
      const offline = new OfflineAudioContext(1, audioCtx.sampleRate*duration, audioCtx.sampleRate);

      // curve normaliseren naar audio samples
      const samples = Math.floor(duration*audioCtx.sampleRate);
      let curve = new Float32Array(samples);
      for(let i=0; i<samples; i++){
        const x = Math.floor(i/samples * curveCanvas.width);
        curve[i] = curvePoints[x] ?? 0;
      }

      const scratchBuf = offline.createBuffer(1, samples, audioCtx.sampleRate);
      const inData = recordedBuffer.getChannelData(0);
      const outData = scratchBuf.getChannelData(0);

      for(let i=0; i<samples; i++){
        let pos = Math.floor(((curve[i]+1)/2)*(inData.length-1));
        outData[i] = inData[pos];
      }

      const src = offline.createBufferSource();
      src.buffer = scratchBuf;
      src.connect(offline.destination);
      src.start();
      const rendered = await offline.startRendering();

      // afspelen
      const play = audioCtx.createBufferSource();
      play.buffer = rendered;
      play.connect(audioCtx.destination);
      play.start();

      // export
      const wav = audioBufferToWav(rendered);
      const blob = new Blob([new DataView(wav)], {type:"audio/wav"});
      const url = URL.createObjectURL(blob);
      output.innerHTML = `<audio controls src="${url}"></audio><br>
        <a href="${url}" download="scratch.wav">üíæ Download</a>`;
    };

    // AudioBuffer ‚Üí WAV
    function audioBufferToWav(buffer) {
      const numOfChan = buffer.numberOfChannels;
      const length = buffer.length * numOfChan * 2 + 44;
      const buffer2 = new ArrayBuffer(length);
      const view = new DataView(buffer2);
      const channels = [];
      let pos = 0;

      function setUint16(data) { view.setUint16(pos, data, true); pos += 2; }
      function setUint32(data) { view.setUint32(pos, data, true); pos += 4; }

      setUint32(0x46464952); setUint32(length - 8); setUint32(0x45564157);
      setUint32(0x20746d66); setUint32(16); setUint16(1); setUint16(numOfChan);
      setUint32(buffer.sampleRate); setUint32(buffer.sampleRate*2*numOfChan);
      setUint16(numOfChan*2); setUint16(16);
      setUint32(0x61746164); setUint32(length - pos - 4);

      for (let i = 0; i < numOfChan; i++)
        channels.push(buffer.getChannelData(i));

      let offset = 0;
      while (pos < length) {
        for (let i = 0; i < numOfChan; i++) {
          let sample = Math.max(-1, Math.min(1, channels[i][offset]));
          sample = sample < 0 ? sample * 0x8000 : sample * 0x7fff;
          view.setInt16(pos, sample, true);
          pos += 2;
        }
        offset++;
      }
      return buffer2;
    }

    // init curve canvas
    drawCurve();
  </script>
</body>
</html>